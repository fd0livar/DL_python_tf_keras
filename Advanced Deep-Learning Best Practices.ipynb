{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Advanced Deep-Learning Best Practices.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1_lwOawpK_mLxL7DYYuHvpJBQBHMeAWw8","authorship_tag":"ABX9TyPHeM+BgJleAXerw7lmQbtV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"E1lCTQ-wgT9l","colab_type":"code","outputId":"807c839c-3154-48b7-f0d9-19a81bae4a24","executionInfo":{"status":"ok","timestamp":1587753887425,"user_tz":-120,"elapsed":731,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%tensorflow_version 1.x"],"execution_count":0,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mrfZM8--gaw-","colab_type":"code","outputId":"5dfbe583-8a0d-4b24-f2c5-6bea6745bdaf","executionInfo":{"status":"ok","timestamp":1587753906270,"user_tz":-120,"elapsed":5420,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":276}},"source":["!pip install keras==2.0.8"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting keras==2.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/3f/d117d6e48b19fb9589369f4bdbe883aa88943f8bb4a850559ea5c546fefb/Keras-2.0.8-py2.py3-none-any.whl (276kB)\n","\r\u001b[K     |█▏                              | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.4.1)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.18.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.0.8) (1.12.0)\n","\u001b[31mERROR: textgenrnn 1.4.1 has requirement keras>=2.1.5, but you'll have keras 2.0.8 which is incompatible.\u001b[0m\n","Installing collected packages: keras\n","  Found existing installation: Keras 2.3.1\n","    Uninstalling Keras-2.3.1:\n","      Successfully uninstalled Keras-2.3.1\n","Successfully installed keras-2.0.8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sCEJmiAKAXxD","colab_type":"text"},"source":["## 7.1.1 Introduction to the functional API"]},{"cell_type":"code","metadata":{"id":"LxZtVkKXPJDP","colab_type":"code","outputId":"d906fa84-2146-4399-8fad-2be87a49fed3","executionInfo":{"status":"ok","timestamp":1587753919129,"user_tz":-120,"elapsed":6784,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":166}},"source":["from keras import Input, layers\n","\n","input_tensor = Input(shape=(32, ))\n","dense = layers.Dense(32, activation='relu')\n","output_tensor = dense(input_tensor)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oU6DRxJ4P9lM","colab_type":"code","outputId":"f0cf7e6f-d45e-42d3-fe47-9d3d7b50e918","executionInfo":{"status":"ok","timestamp":1587753937822,"user_tz":-120,"elapsed":783,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":293}},"source":["from keras.models import Sequential, Model\n","from keras import layers\n","from keras import Input\n","\n","# a model\n","seq_model = Sequential()\n","seq_model.add(layers.Dense(32, activation='relu', input_shape=(64, )))\n","seq_model.add(layers.Dense(32, activation='relu'))\n","seq_model.add(layers.Dense(10, activation='softmax'))\n","\n","# its equivalent\n","input_tensor = Input(shape=(64, ))\n","x = layers.Dense(32, activation='relu')(input_tensor)\n","x = layers.Dense(32, activation='relu')(x)\n","output_tensor = layers.Dense(10, activation='softmax')(x)\n","\n","# the Model class, createsa model from an input and an output tensor\n","model = Model(input_tensor, output_tensor)\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_4 (InputLayer)         (None, 64)                0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 32)                2080      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 32)                1056      \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 10)                330       \n","=================================================================\n","Total params: 3,466\n","Trainable params: 3,466\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"87z90_cWRtij","colab_type":"text"},"source":["Let's see what happens when creating a model from two unrelated tensors"]},{"cell_type":"code","metadata":{"id":"ncTsLNlWRQ1Q","colab_type":"code","outputId":"89d7d3f2-c69e-4afd-aead-2e697e9185a0","executionInfo":{"status":"error","timestamp":1587753923310,"user_tz":-120,"elapsed":719,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":363}},"source":["unrelated_input = Input(shape=(32, ))\n","bad_model = model = Model(unrelated_input, output_tensor)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a682a56a30ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                                 \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1789\u001b[0m                                 \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1791\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_2:0\", shape=(?, 64), dtype=float32) at layer \"input_2\". The following previous layers were accessed without issue: []"]}]},{"cell_type":"markdown","metadata":{"id":"3EEgql8XR-Lm","colab_type":"text"},"source":["Keras couldn't connect both tensors. \n","\n","Now, to compile the model we do:"]},{"cell_type":"code","metadata":{"id":"6Gz1QdcmSNIm","colab_type":"code","outputId":"96e7a4fb-d2db-40e9-b0fa-4cbd41e27528","executionInfo":{"status":"ok","timestamp":1587753941745,"user_tz":-120,"elapsed":934,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":403}},"source":["model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","\n","import numpy as np\n","x_train = np.random.random((1000, 64))\n","y_train = np.random.random((1000, 10))\n","\n","model.fit(x_train, y_train, \n","          epochs=10, \n","          batch_size=128)\n","\n","score = model.evaluate(x_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","1000/1000 [==============================] - 0s - loss: 11.6962     \n","Epoch 2/10\n","1000/1000 [==============================] - 0s - loss: 11.6137     \n","Epoch 3/10\n","1000/1000 [==============================] - 0s - loss: 11.5956     \n","Epoch 4/10\n","1000/1000 [==============================] - 0s - loss: 11.5854     \n","Epoch 5/10\n","1000/1000 [==============================] - 0s - loss: 11.5792     \n","Epoch 6/10\n","1000/1000 [==============================] - 0s - loss: 11.5750     \n","Epoch 7/10\n","1000/1000 [==============================] - 0s - loss: 11.5719     \n","Epoch 8/10\n","1000/1000 [==============================] - 0s - loss: 11.5687     \n","Epoch 9/10\n","1000/1000 [==============================] - 0s - loss: 11.5660     \n","Epoch 10/10\n","1000/1000 [==============================] - 0s - loss: 11.5641     \n","  32/1000 [..............................] - ETA: 1s"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"V0C9jgtLSwDe","colab_type":"text"},"source":["## 7.1.2 Multi-input models\n","\n","To merge the different branches of a multi-input model we can use keras layers such as: `keras.layers.add`,`keras.layers.concatenate`, etc. \n","\n","Let's create a *question-answering model*, which has 2 inputs and one output. The inputs are a question and a text snippet providing information to be used for answering the question. In the simplest model, the amswer is one word, obtained via a softmax activation."]},{"cell_type":"markdown","metadata":{"id":"J-tG2uXVT-S5","colab_type":"text"},"source":["### L7.1 Functional API implementation of a two-input question-answering model"]},{"cell_type":"code","metadata":{"id":"dlyas_GQUEg5","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras import layers\n","from keras import Input\n","\n","text_vocabulary_size = 10000\n","question_vocabulary_size = 10000\n","answer_vocabulary_size = 500\n","\n","text_input = Input(shape=(None, ), dtype='int32', name='text')\n","embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input) # Embedding(input, output)\n","encoded_text = layers.LSTM(32)(embedded_text)\n","\n","question_input = Input(shape=(None,), dtype='int32', name='question')\n","embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n","encoded_question = layers.LSTM(16)(embedded_question)\n","\n","concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n","\n","answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)\n","\n","model = Model([text_input, question_input], answer)\n","model.compile(optimizer='rmsprop', \n","              loss='categorical_crossentropy', \n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2cFZ4YXTW837","colab_type":"text"},"source":["### L7.2 Feeding data to a multi-input model"]},{"cell_type":"code","metadata":{"id":"6srWIQO9aWi1","colab_type":"code","outputId":"720a26de-a65b-48ef-9a09-3db37311e7d2","executionInfo":{"status":"ok","timestamp":1587754681098,"user_tz":-120,"elapsed":578,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":458}},"source":["import numpy as np\n","import keras\n","\n","num_samples = 1000\n","max_length = 100\n","\n","text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n","\n","question = np.random.randint(1, \n","                             question_vocabulary_size, \n","                             size=(num_samples, max_length))\n","\n","# answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n","answers = np.random.randint(answer_vocabulary_size, size=(num_samples))\n","answers = keras.utils.to_categorical(answers, answer_vocabulary_size)\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["____________________________________________________________________________________________________\n","Layer (type)                     Output Shape          Param #     Connected to                     \n","====================================================================================================\n","text (InputLayer)                (None, None)          0                                            \n","____________________________________________________________________________________________________\n","question (InputLayer)            (None, None)          0                                            \n","____________________________________________________________________________________________________\n","embedding_5 (Embedding)          (None, None, 64)      640000      text[0][0]                       \n","____________________________________________________________________________________________________\n","embedding_6 (Embedding)          (None, None, 32)      320000      question[0][0]                   \n","____________________________________________________________________________________________________\n","lstm_5 (LSTM)                    (None, 32)            12416       embedding_5[0][0]                \n","____________________________________________________________________________________________________\n","lstm_6 (LSTM)                    (None, 16)            3136        embedding_6[0][0]                \n","____________________________________________________________________________________________________\n","concatenate_3 (Concatenate)      (None, 48)            0           lstm_5[0][0]                     \n","                                                                   lstm_6[0][0]                     \n","____________________________________________________________________________________________________\n","dense_16 (Dense)                 (None, 500)           24500       concatenate_3[0][0]              \n","====================================================================================================\n","Total params: 1,000,052\n","Trainable params: 1,000,052\n","Non-trainable params: 0\n","____________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_gbNFma_b04T","colab_type":"code","outputId":"aa23192c-d5e1-4dda-8b71-e18e72065b27","executionInfo":{"status":"ok","timestamp":1587754803820,"user_tz":-120,"elapsed":36447,"user":{"displayName":"Fa Oli","photoUrl":"","userId":"10660454401649634141"}},"colab":{"base_uri":"https://localhost:8080/","height":825}},"source":["# one way to train the model by using a list of inputs\n","print('training with the first method: giving a list of inputs')\n","model.fit([text, question], answers, \n","          epochs=10, \n","          batch_size=128)\n","\n","# second way is to give a dictionary (this only works if inputs are named using `name=`)\n","print()\n","print('training with the second method: giving a dictionary')\n","model.fit({'text': text, 'question': question}, answers,\n","          epochs=10, \n","          batch_size=128)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["training with the first method: giving a list of inputs\n","Epoch 1/10\n","1000/1000 [==============================] - 1s - loss: 6.2139 - acc: 0.0020     \n","Epoch 2/10\n","1000/1000 [==============================] - 1s - loss: 6.1743 - acc: 0.0150     \n","Epoch 3/10\n","1000/1000 [==============================] - 1s - loss: 6.0761 - acc: 0.0060     \n","Epoch 4/10\n","1000/1000 [==============================] - 1s - loss: 6.0216 - acc: 0.0030     \n","Epoch 5/10\n","1000/1000 [==============================] - 1s - loss: 5.9910 - acc: 0.0070     \n","Epoch 6/10\n","1000/1000 [==============================] - 1s - loss: 5.9666 - acc: 0.0060     \n","Epoch 7/10\n","1000/1000 [==============================] - 1s - loss: 5.9351 - acc: 0.0080     \n","Epoch 8/10\n","1000/1000 [==============================] - 1s - loss: 5.8861 - acc: 0.0080     \n","Epoch 9/10\n","1000/1000 [==============================] - 1s - loss: 5.8323 - acc: 0.0090     \n","Epoch 10/10\n","1000/1000 [==============================] - 1s - loss: 5.7816 - acc: 0.0090     \n","\n","training with the second method: giving a dictionary\n","Epoch 1/10\n","1000/1000 [==============================] - 1s - loss: 5.7282 - acc: 0.0150     \n","Epoch 2/10\n","1000/1000 [==============================] - 1s - loss: 5.6669 - acc: 0.0170     \n","Epoch 3/10\n","1000/1000 [==============================] - 1s - loss: 5.5994 - acc: 0.0210     \n","Epoch 4/10\n","1000/1000 [==============================] - 1s - loss: 5.5260 - acc: 0.0200     \n","Epoch 5/10\n","1000/1000 [==============================] - 1s - loss: 5.4660 - acc: 0.0290     \n","Epoch 6/10\n","1000/1000 [==============================] - 1s - loss: 5.3974 - acc: 0.0320     \n","Epoch 7/10\n","1000/1000 [==============================] - 1s - loss: 5.3349 - acc: 0.0410     \n","Epoch 8/10\n","1000/1000 [==============================] - 1s - loss: 5.2885 - acc: 0.0370     \n","Epoch 9/10\n","1000/1000 [==============================] - 1s - loss: 5.2166 - acc: 0.0500     \n","Epoch 10/10\n","1000/1000 [==============================] - 1s - loss: 5.1764 - acc: 0.0540     \n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f184dab5a58>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"mfKnVGIejxNv","colab_type":"text"},"source":["## 7.1.3 Multi-outputs models\n","\n","We can also create models with multiple outputs. For example, we could predict multiple properties from a single data input.    \n","Let's see an example where we predict attributes of a person, such as age, gender, and income level, from social media posts. \n","\n","### L7.3 Functional API implementation of a three-output model"]},{"cell_type":"markdown","metadata":{"id":"Op5dpiKA5z_X","colab_type":"text"},"source":["```python\n","from keras import layers\n","from keras import Input\n","from keras.models import Model\n","\n","vocabulary_size = 50000\n","num_income_groups = 10\n","\n","posts_input = Input(shape=(None, ), dtype='int32', name='posts')\n","embedded_posts = layers.Embedding(256, vocabulary_size)(posts_input)\n","\n","x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.MaxPooling1D(5)(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.Conv1D(256, 5, activation='relu')(x)\n","x = layers.GlobalMaxPooling1D()(x)\n","x = layers.Dense(128, activation='relu')(x)\n","\n","age_prediction = layers.Dense(1, \n","                              name='age')(x)\n","income_prediction = layers.Dense(num_income_groups, \n","                                 activation='softmax', \n","                                 name='income')(x)\n","gender_prediction = layers.Dense(1, \n","                                 activation='sigmoid', \n","                                 name='gender')(x)\n","\n","model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])  \n","```                              "]},{"cell_type":"markdown","metadata":{"id":"N33CUR8f8S3Z","colab_type":"text"},"source":["An important difference when training a model with multiple outputs is the specification of the loss function. Each output should have its own loss function depending on the type of task. But to optimize the whole model, gradient descent requires a *scalar* value to minimize. To obtain a scalar value from the different loss funcions, you must combine them by summing them all. In Keras, this is done by giving a list or a dictionary in the `compile` step to specify different objects for different outputs. Internally, the different loss functions will be summed into a single value which will be minimized during training. \n","\n","\n","### L7.4 Compilation options of a multi-output model: multiple losses\n","First method: Giving a list of loss functions:\n","```python\n","model.compile(optimizer='rmsprop',\n","              loss=['mse', 'categorical_cross_entropy', 'binary_crossentropy'])\n","```\n","\n","Second method: Giving a dictionary of loss functions indicating the name of the layer:\n","```python\n","model.compile(optimizer='rmsprop', \n","              loss={'age': 'mse', \n","                    'income': 'categorical_crossentropy', \n","                    'gender': 'binary_crossentropy'})               \n","```\n","\n","What is even more important, is to know the possible range of the different loss function values, since this can draw the attention of the minimization process into one of the tasks. To solve this, you can give weights to the different losses so their importance is similar.\n","\n","### L7.5 Compilation options of a multi-output model: loss weighting\n","List method:\n","```python\n","model.compile(optimizer='rmsprop', \n","              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'], \n","              loss_weights=[0.25, 1., 10.])\n","```\n","Dictionary method:\n","```python\n","model.compile(optimizer='rmsprop',\n","              loss={'age': 'mse',\n","                    'income': 'categorical_crossentropy',\n","                    'gender': 'binary_crossentropy'},\n","              loss_weights={'age': 0.25,\n","                            'income': 1.,\n","                            'gender': 10.}\n","```\n","\n","For training, you can pass Numpy data to the model, in the same way as for the multiple-input models:\n","\n","### L7.6 Feeding data to a multi-output model\n","\n","List method\n","```python\n","model.fit(posts, [age_targets, income_targets,gender_targets],\n","          epochs=10, batch_size=64)\n","```\n","Dictionary method:\n","```python\n","model.fit(posts, {'age': age_targets,\n","                  'income': income_targets,\n","                  'gender': gender_targets},\n","          epochs=10, batch_size=64)\n","```"]},{"cell_type":"markdown","metadata":{"id":"tH4hY7QDXVNN","colab_type":"text"},"source":["## 7.1.4 Directed acyclic graphs of layers\n","\n","### Inception modules\n","\n","This is a popular type of network architecture for convolutional neural networks, developed by Christian Szegedy and colleagues at Google in 2013-2014 [(publication)](https://arxiv.org/abs/1409.4842). It is inspired by the *network-in-network* architecture [(publication)](https://arxiv.org/abs/1312.4400). \n","\n","The inception network consist of a stack of modules that look like small networks, having several parallel branches. The branches have 1x1 convolutions, 3x3 convolutions, AvgPool2D, etc. They end with a concatenarion of the resulting features. The advantage of this network is that it separately learns channel-wise and spatial features, which is more efficient than doing all together. You can have modules with different complexities. \n","\n","#### *The purpose of 1x1 convolutions (pointwise convolutions)*  \n","It's equivalent to running each tile through a `Dense` layer: it mixes information from the channels of the input tensor, but it won't mix information across space. \n","\n","There is another model called [Xception](https://arxiv.org/abs/1610.02357) (extreme inception), that separates the learning of spatial and channel-wise features to its logical extreme. It has rougly the same number of parameters as Inception V3, but it shows better runtime performance and higher accuracy in ImageNet and other large-scale datasets.\n","\n","### Residual Connections\n","\n","This is a common network component found in many post-2015 network architectures. They were introduced by [He et al](https://arxiv.org/abs/1512.03385). They tackle 2 common problems in deep-learning models: vanishing gradients and representational bottlenecks. (in general, beneficial for more than 10 layers.) \n","\n","It consist of making the output of a layer available as input to a later layer. \n","\n","Both outputs are then summed to create a unique activation, assuming both activations are the same size. If the are not, then you should use a transformation to reshape the earlier activation (`Dense` layer, 1x1 conv. w/o activation).  \n","\n","Here's an example when they are the same size (assuming a 4D input tensor `x`):\n","\n","```python\n","from keras import layers\n","\n","x = ...\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n","\n","y = layers.add([y, x])\n","```\n","\n","And now a residual connection when the feature-maps sizes differ:\n","\n","```python\n","from keras import layers\n","\n","x = ...\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n","y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n","y = layers.MaxPooling2D(2, strides=2)(y)\n","\n","residual = layers.Conv2D(128, 1, strides=2, padding='same')(x) # Uses a 1x1 conv. to linearly downsample \n","                                                               # the original x tensor to the same shape as y\n","\n","y = layers.add([y, residual])\n","```"]},{"cell_type":"markdown","metadata":{"id":"zAnvRtXRg6Zs","colab_type":"text"},"source":["### Important concepts\n","### - Representational bottlenecks in deep learning:  \n"," This concept can be undertood in the context of a network of Sequential `Dense` layers. If one layer has too few units, its capacity to represent the information will be more restricted than a layer with more units. This affects the amount of information passing to the next layers in the network, as any information loss will never be recover afterwards. Residual connections come to partially solve this issue for deep-learning models. \n","### - Vanishing gradients in deep learning:  \n","Backpropagation is the core algorithm involved in the training of neural networks. It work propagating a feedback signal from the output back to the earlier layers. As it is a gradient, this signal may be too subtle or even effectively zero after many layers, which means earlier layer cannnot be trained.  \n","This vanishing signal occurs with deep networks as well as with recurrent neural network with very long sequences. For LSTM layers, a carry track is implemented to propagate information parallel to the main processing section. Residual connections work similarly but in a simpler way. They introduce a linear information carry track parallel to the main layer track, thus helping to propagate gradients through arbitrarily deep stacks of layers. "]},{"cell_type":"markdown","metadata":{"id":"0UtBaWPtOCuG","colab_type":"text"},"source":["## 7.1.5 Layer weight sharing\n","\n","This is another important feature of the functional API, reusing a layer instance. When calling a layer instancce twice, we reuse the same weights. This allows to build models with shared branches, i.e. they share and learn the same representations simultaneously for different sets of inputs.  \n","\n","For example, a model that looks for the semantic similarity between two sentences can use the same layer to process both input sentences in parallel. We can use a LSTM layer in what is called a *Siamese* LSTM model, or *shared* LSTM. \n","\n","Let's look at the implementation:\n","\n","```python\n","from keras import layers\n","from keras import Input\n","from keras.models import Model\n","\n","lstm = layers.LSTM(32) # We instantiate a single LSTM layer, once\n","\n","left_input = Input(shape=(None, 128))\n","left_output = lstm(left_input)\n","\n","right_input = Input(shape=(None, 128))\n","right_output = lstm(right_input) # We call the same layer\n","\n","# We wuild the classifier on top\n","merged = layers.concatenate([left_output, right_output], axis=-1)\n","predictions = layers.Dense(1, activation='sigmoid')(merged)\n","\n","# We instantiate and train the model \n","# The weights of the LSTM layer are updated based on both inputs\n","model = Model([left_input, right_input], predictions)\n","model.fit([left_data, right_data], targets)\n","```"]},{"cell_type":"markdown","metadata":{"id":"2qCRZHVmSur1","colab_type":"text"},"source":["## 7.1.6 Models as layers\n","\n","When using the functional API, models can be used as layers! This is true for both `Sequential` and `Model` classes. You can call a model on an input tensor and get an output tensor:\n","```python\n","y = model(x)\n","```\n","With a multi-input/output model, you should use a lists of tensors:\n","```python\n","y1, y2 = model([x1, x2])\n","```\n","Following the *shared weights* behaviour when instantiating a layer more than once, here the same happens, you reuse the model's weights.\n","\n","An example of a *shared* model is a vision model that uses a dual camera as its input, to detect depth. Here you don't need two independent models to extract visual features for each camera before merging them. That processing can be shared across the two inputs: by using shared models, i.e. shared *layers*. Here is an implementation of this Siamese vision model based in the Xception network (convolutional base only):\n","\n","```python\n","from keras import layers\n","from keras import applications\n","from keras import Input\n","\n","xception_base = applications.Xception(weights=None,\n","include_top=False)\n","\n","# The inputs are 250x250 RGB images\n","left_input = Input(shape=(250, 250, 3))\n","right_input = Input(shape=(250, 250, 3))\n","\n","# We call the same vision model twice\n","left_features = xception_base(left_input)\n","right_features = xception_base(right_input)\n","\n","merged_features = layers.concatenate([left_features, right_features], axis=-1)\n","```"]},{"cell_type":"markdown","metadata":{"id":"lQgExsO-WciQ","colab_type":"text"},"source":["## 7.1.7 Wrapping up\n","\n","Concepts covered in the introduction to the Keras functional API:\n","- To use `Model` when `Sequential` doesn't allow to build the required model\n","- How to build models with several inputs/outputs, complex internal network topology\n","- How to reuse weights of layers or models across different processing branches, by calling the same layer/model instance more than once"]}]}