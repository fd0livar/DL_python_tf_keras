{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":26,"outputs":[{"output_type":"stream","text":"/kaggle/input/cats-anddogs-small-pre-vgg16/cat_and_dogs_small_pre_vgg16.h5\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\n/kaggle/input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv\n/kaggle/input/catdogs-small-finetune/cat_and_dogs_small_finetune.h5\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport time, shutil\nfrom keras import optimizers\nfrom keras import layers, models\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import VGG16\nfrom keras.applications.imagenet_utils import preprocess_input","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_dir_train = '/kaggle/original_data/train'\nif not os.path.exists(original_dir_train):\n    os.makedirs(original_dir_train)\n    \n# I still have to unzip `test` ","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I unzip the training files to the folder `/kaggle/original_data/train`  "},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip -d /kaggle/original_data/train","execution_count":29,"outputs":[{"output_type":"stream","text":"Archive:  /kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\nreplace /kaggle/original_data/train/train/cat.0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/small_data'\nif not os.path.exists(base_dir):\n    os.mkdir(base_dir)","execution_count":36,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's create the folders where we'll save the divided original training data (training, validation and test)."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = os.path.join(base_dir, 'train')\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\n    \nvalidation_dir = os.path.join(base_dir, 'validation')\nif not os.path.exists(validation_dir):\n    os.mkdir(validation_dir)\n\ntest_dir = os.path.join(base_dir, 'test')\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We create the folder for cats and dogs inside each of the recently created folders"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats_dir = os.path.join(train_dir, 'cats')\nif not os.path.exists(train_cats_dir):\n    os.mkdir(train_cats_dir)\n    \ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nif not os.path.exists(train_dogs_dir):\n    os.mkdir(train_dogs_dir)\n\nvalidation_cats_dir = os.path.join(validation_dir, 'cats')\nif not os.path.exists(validation_cats_dir):\n    os.mkdir(validation_cats_dir)\n\nvalidation_dogs_dir = os.path.join(validation_dir, 'dogs')\nif not os.path.exists(validation_dogs_dir):\n    os.mkdir(validation_dogs_dir)\n\ntest_cats_dir = os.path.join(test_dir, 'cats')\nif not os.path.exists(test_cats_dir):\n    os.mkdir(test_cats_dir)\n\ntest_dogs_dir = os.path.join(test_dir, 'dogs')\nif not os.path.exists(test_dogs_dir):\n    os.mkdir(test_dogs_dir)","execution_count":38,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We copy the pictures of cats from `train.zip` into the three cat folders\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_path_dataset = '/kaggle/original_data/train/train'\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(train_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(validation_cats_dir, fname)\n    shutil.copyfile(src, dst)\n    \nfnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(test_cats_dir, fname)\n    shutil.copyfile(src, dst)","execution_count":39,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we copy the pictures of dogs into their folders"},{"metadata":{"trusted":true},"cell_type":"code","source":"fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(train_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(validation_dogs_dir, fname)\n    shutil.copyfile(src, dst)\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\nfor fname in fnames:\n    src = os.path.join(original_path_dataset, fname)\n    dst = os.path.join(test_dogs_dir, fname)\n    shutil.copyfile(src, dst)","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Counting the elements in each folder:"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('total training cat images: {}'.format(len(os.listdir(train_cats_dir))))\nprint('total training dog images: {}'.format(len(os.listdir(train_dogs_dir))))\nprint('total validation cat images: {}'.format(len(os.listdir(validation_cats_dir))))\nprint('total validation dog images: {}'.format(len(os.listdir(validation_dogs_dir))))\nprint('total test cat images: {}'.format(len(os.listdir(test_cats_dir))))\nprint('total test dog images: {}'.format(len(os.listdir(test_dogs_dir))))","execution_count":41,"outputs":[{"output_type":"stream","text":"total training cat images: 1000\ntotal training dog images: 1000\ntotal validation cat images: 500\ntotal validation dog images: 500\ntotal test cat images: 500\ntotal test dog images: 500\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"--------------------------\nNow we can start building the keras model:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We compile it now:"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', \n              optimizer=optimizers.RMSprop(lr=1e-4),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As our data has many different sizes, we create a data preprocessing step, were data is imported in batches, transformed to RGB, each pixel rescaled to a `0-1` range and resized to a `150x150 px` size:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir, \n    target_size=(150, 150), \n    batch_size=20, \n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir, \n    target_size=(150, 150), \n    batch_size=20, \n    class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 2000 images for training and 1000 images for validation. We can check the sizes of the images and the batch:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the shape of the images and labels batch\nimport PIL\nfor data_batch, labels_batch in train_generator:\n    print('data batch shape: {}'.format(data_batch.shape))\n    print('labels batch shape: {}'.format(labels_batch.shape))\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we have everything prepared to train our model with the training data and validate it using the validation data we have created."},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.perf_counter()\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=50)\n\nelapsed = time.perf_counter() - start\nprint('Elapsed %.3f seconds.' % elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GPU time: 258.947 seconds"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/cat_and_dogs_small_1.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r*', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r*', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see the model is overfitting, as the accuracy stops increasing for the validations the whereas keeps increasing for the training set. \n\nWe'll add regularization to the model, specifically Data Augmentation and Dropout."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D((2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dropout(0.5))\n\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we create the data generator with parameters for data augmentation:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255, \n    rotation_range=40, \n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir, \n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir, \n    target_size=(150, 150), \n    batch_size=32, \n    class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we train the model for more epochs, as the increment in accuracy will be slower due to the regularization "},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.perf_counter()\n\nhistory2 = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=50)\n\nelapsed = time.perf_counter() - start\nprint('Elapsed %.3f seconds.' % elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GPU time: 2615.118 seconds -> 43.5853 minutes"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/cat_and_dogs_small_augmentation.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, we plot the metrics:"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history2.history['acc']\nval_acc = history2.history['val_acc']\nloss = history2.history['loss']\nval_loss = history2.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r*', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r*', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We couldl continue adjusting model parameters such as the number of filters per convolution layer, or the number of layers in the network, but we will use another approach:\n\n### Using a pretrained convnet\n\nWe'll use the VGG16 model [[ref]](https://arxiv.org/abs/1409.1556), trained on the `imagenet` dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's do feature extraction with data augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is importan to freeze the convolutional base of the VGG16 model. This prevents the already trained weights to be updated during training. "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(model.trainable_weights))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(model.trainable_weights))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, we train the model, but now with this new convolutional base:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    #rescale=1./255,\n    preprocessing_function=preprocess_input,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(150, 150),\n    batch_size=20,\n    class_mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n    optimizer=optimizers.RMSprop(lr=2e-5),\n    metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.perf_counter()\n\nhistory_vgg16 = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=50, \n    verbose=2)\n\nelapsed = time.perf_counter() - start\nprint('Elapsed %.3f seconds.' % elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GPU time: 533.225 seconds -> 8.887 minutes"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras \nkeras.__version__","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/cat_and_dogs_small_pre_vgg16.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's plot the metrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_vgg16.history['acc']\nval_acc = history_vgg16.history['val_acc']\nloss = history_vgg16.history['loss']\nval_loss = history_vgg16.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r*', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r*', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We obtained a validation accuracy of about 96%"},{"metadata":{},"cell_type":"markdown","source":"To continue with the training, let's load the saved model, which was previously trained here in kaggle. \n\nThis model consists of a convnet base (vgg16) pretrained on the imagenet dataset, plus a fully connected classiffier on top. \n\nWe will now fine-tune this model by unfreezing the first block of layers of the vgg16 section, followed by training the whole model again. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.load_model('/kaggle/input/cats-anddogs-small-pre-vgg16/cat_and_dogs_small_pre_vgg16.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[0].name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[0].trainable = True\nset_trainable = False\nfor layer in model.layers[0].layers:\n    if layer.name == 'block5_conv1':\n        set_trainable = True\n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[0].summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's compile this new form of the model, with the top layers of the convolutional base unfreezed. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.RMSprop(lr=1e-5),\n              metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start = time.perf_counter()\n\nhistory_finetune = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=50)\n\nelapsed = time.perf_counter() - start\nprint('Elapsed %.3f seconds.' % elapsed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"GPU time: 1873.439 seconds -> 31.223 minutes"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history_finetune.history['acc']\nval_acc = history_finetune.history['val_acc']\nloss = history_finetune.history['loss']\nval_loss = history_finetune.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\nplt.plot(epochs, acc, 'bo', label='Training acc')\nplt.plot(epochs, val_acc, 'r*', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='Training loss')\nplt.plot(epochs, val_loss, 'r*', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/cat_and_dogs_small_finetune.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To remove the noise from the plot and have a clear trend, we smooth it using exponential moving averages:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# we first load the last model, which we finetuned\nmodel = models.load_model('/kaggle/input/catdogs-small-finetune/cat_and_dogs_small_finetune.h5')","execution_count":43,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def smooth_curve(points, factor=0.8):\n    smoothed_points = []\n    for point in points:\n        if smoothed_points:\n            previous = smoothed_points[-1]\n            smoothed_points.append(previous * factor + point * (1 - factor))\n        else:\n            smoothed_points.append(point)\n        return smoothed_points","execution_count":44,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"# We can not plot this curve since we didn't save the `history` of the \n#training stage (callbacks)\n\nplt.plot(epochs, smooth_curve(acc), 'bo', label='Smoothed training acc')\nplt.plot(epochs, smooth_curve(val_acc), 'r', label='Smoothed validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\nplt.plot(epochs, smooth_curve(loss), 'bo', label='Smoothed training loss')\nplt.plot(epochs, smooth_curve(val_loss), 'r', label='Smoothed validation loss')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"However we can still evaluate the model on the test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(\n    test_dir, \n    target_size=(150, 150),\n    batch_size=20, \n    class_mode='binary')\n\ntest_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\nprint('test acc: {}'.format(test_acc))","execution_count":48,"outputs":[{"output_type":"stream","text":"Found 1000 images belonging to 2 classes.\ntest acc: 0.968999981880188\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We obtained a 97% test accuracy.\n\nThe main difference with the original competition is that we trained the model using only 2000 samples instead of the original 20000 samples. Showing us that convolutional networks are a powerfull technique for computer vision tasks. "},{"metadata":{},"cell_type":"markdown","source":"### todo\n\n- evaluate the model in the whole `test` folder\n- submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"!unzip /kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip -d /kaggle/otest","execution_count":45,"outputs":[{"output_type":"stream","text":"Archive:  /kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\nreplace /kaggle/otest/test/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"New evaluation, now using the original test folder"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_test_dir = '/kaggle/otest/test'","execution_count":74,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}